{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfgiIgcnyhZ9",
        "outputId": "79bfa7d2-2bc1-472d-816f-5a2a31207d19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Perceptron on AND Gate...\n",
            "Epoch 1, Sample 1: Weights: [0. 0.], Bias: -0.1\n",
            "Epoch 1, Sample 2: Weights: [0. 0.], Bias: -0.1\n",
            "Epoch 1, Sample 3: Weights: [0. 0.], Bias: -0.1\n",
            "Epoch 1, Sample 4: Weights: [0.1 0.1], Bias: 0.0\n",
            "Epoch 2, Sample 1: Weights: [0.1 0.1], Bias: -0.1\n",
            "Epoch 2, Sample 2: Weights: [0.1 0. ], Bias: -0.2\n",
            "Epoch 2, Sample 3: Weights: [0.1 0. ], Bias: -0.2\n",
            "Epoch 2, Sample 4: Weights: [0.2 0.1], Bias: -0.1\n",
            "Epoch 3, Sample 1: Weights: [0.2 0.1], Bias: -0.1\n",
            "Epoch 3, Sample 2: Weights: [0.2 0. ], Bias: -0.2\n",
            "Epoch 3, Sample 3: Weights: [0.1 0. ], Bias: -0.30000000000000004\n",
            "Epoch 3, Sample 4: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 4, Sample 1: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 4, Sample 2: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 4, Sample 3: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 4, Sample 4: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 5, Sample 1: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 5, Sample 2: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 5, Sample 3: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 5, Sample 4: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 6, Sample 1: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 6, Sample 2: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 6, Sample 3: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 6, Sample 4: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 7, Sample 1: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 7, Sample 2: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 7, Sample 3: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 7, Sample 4: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 8, Sample 1: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 8, Sample 2: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 8, Sample 3: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 8, Sample 4: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 9, Sample 1: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 9, Sample 2: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 9, Sample 3: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 9, Sample 4: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 10, Sample 1: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 10, Sample 2: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 10, Sample 3: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "Epoch 10, Sample 4: Weights: [0.2 0.1], Bias: -0.20000000000000004\n",
            "\n",
            "Prediction for [1 1]: 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "  def __init__(self, learning_rate=0.01, epochs=100):\n",
        "    # Hyperparameters\n",
        "    self.lr = learning_rate\n",
        "    self.epochs = epochs\n",
        "    self.weights = None\n",
        "    self.bias = 0\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    # Initialize weights to zeros based on number of inputs\n",
        "    self.weights = np.zeros(X.shape[1])\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(self.epochs):\n",
        "      for i in range(X.shape[0]):\n",
        "        # 1. Prediction (Step Function)\n",
        "        linear_output = np.dot(X[i], self.weights) + self.bias\n",
        "        y_pred = 1 if linear_output >= 0 else 0\n",
        "\n",
        "        # 2. Calculate Error\n",
        "        error = y[i] - y_pred\n",
        "\n",
        "        # 3. Update Weights and Bias\n",
        "        self.weights += self.lr * error * X[i]\n",
        "        self.bias += self.lr * error\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Sample {i+1}: Weights: {self.weights}, Bias: {self.bias}')\n",
        "\n",
        "  def predict(self, x):\n",
        "    # Predict for a single input\n",
        "    linear_output = np.dot(x, self.weights) + self.bias\n",
        "    return 1 if linear_output >= 0 else 0\n",
        "\n",
        "# --- Driver Code ---\n",
        "# Data: AND Gate Logic\n",
        "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_train = np.array([0, 0, 0, 1])\n",
        "\n",
        "# Create and Train Perceptron\n",
        "print(\"Training Perceptron on AND Gate...\")\n",
        "model = Perceptron(learning_rate=0.1, epochs=10)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Test the model\n",
        "test_point = np.array([1, 1])\n",
        "prediction = model.predict(test_point)\n",
        "print(f\"\\nPrediction for {test_point}: {prediction}\")"
      ]
    }
  ]
}