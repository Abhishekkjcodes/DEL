{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-2d2raMs10S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Load IMDb dataset (most common 10k words)\n",
        "max_words = 10000\n",
        "max_len = 200\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_words)\n",
        "\n",
        "# 2) Pad sequences so all reviews have equal length\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test  = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "# 3) Build model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=64, input_length=max_len),\n",
        "    LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# 4) Train\n",
        "history = model.fit(X_train, y_train, epochs=5,\n",
        "                    batch_size=128, validation_split=0.2)\n",
        "\n",
        "# 5) Evaluate\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", acc)\n",
        "\n",
        "# 6) Predict custom text\n",
        "word_index = imdb.get_word_index()\n",
        "print(word_index)\n",
        "def encode_text(text):\n",
        "    words = text.lower().split()\n",
        "    encoded = [word_index.get(w, 2) for w in words]   # 2 = unknown token\n",
        "    return pad_sequences([encoded], maxlen=max_len)\n",
        "\n",
        "def sentiment(text):\n",
        "    pred = model.predict(encode_text(text))[0][0]\n",
        "    return \"Positive\" if pred > 0.5 else \"Negative\"\n",
        "\n",
        "print(sentiment(\"This movie was great, I loved it!\"))\n",
        "print(sentiment(\"Worst movie I have ever seen.\"))\n",
        "\n",
        "# 7) Plot accuracy\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='validation')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 8) Plot loss\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='validation')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}