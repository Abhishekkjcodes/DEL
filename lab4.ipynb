{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e217e2",
   "metadata": {},
   "source": [
    "# Lab 3: Deep NN: GD vs SGD (Iris) â€” cleaned\n",
    "\n",
    "Simplified and cleaned code from your lab manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 3: Deep NN optimized with Gradient Descent vs SGD (Iris)\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1,1)\n",
    "\n",
    "# One-hot encode targets\n",
    "onehot = OneHotEncoder(sparse=False)\n",
    "y_onehot = onehot.fit_transform(y)\n",
    "\n",
    "# Train/test split and scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(64, input_shape=(X_train_scaled.shape[1],), activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Gradient Descent (batch training)\n",
    "gd_optimizer = SGD(learning_rate=0.01)\n",
    "gd_model = create_model()\n",
    "gd_model.compile(optimizer=gd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "gd_history = gd_model.fit(X_train_scaled, y_train, epochs=50, batch_size=X_train_scaled.shape[0], validation_data=(X_test_scaled, y_test), verbose=0)\n",
    "\n",
    "# Stochastic Gradient Descent (batch_size=1)\n",
    "sgd_optimizer = SGD(learning_rate=0.01)\n",
    "sgd_model = create_model()\n",
    "sgd_model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "sgd_history = sgd_model.fit(X_train_scaled, y_train, epochs=50, batch_size=1, validation_data=(X_test_scaled, y_test), verbose=0)\n",
    "\n",
    "# Plot losses and accuracies\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(gd_history.history['loss'], label='Train Loss (GD)')\n",
    "plt.plot(gd_history.history['val_loss'], label='Val Loss (GD)')\n",
    "plt.title('GD: Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(gd_history.history['accuracy'], label='Train Acc (GD)')\n",
    "plt.plot(gd_history.history['val_accuracy'], label='Val Acc (GD)')\n",
    "plt.title('GD: Accuracy'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend()\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(sgd_history.history['loss'], label='Train Loss (SGD)')\n",
    "plt.plot(sgd_history.history['val_loss'], label='Val Loss (SGD)')\n",
    "plt.title('SGD: Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(sgd_history.history['accuracy'], label='Train Acc (SGD)')\n",
    "plt.plot(sgd_history.history['val_accuracy'], label='Val Acc (SGD)')\n",
    "plt.title('SGD: Accuracy'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend()\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4afacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Lab 3"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
